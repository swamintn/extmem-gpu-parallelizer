									INTRO
Parallel recursive DP problems using GPU, with data residing in the external
memory
	
									IMPLEMENTATION OF APSP:

1) First, form a Z-morton / row-major layout for the input
(http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7161519)


Take r = 4, d = 2 and design r-way R-DP (Pg 118 of thesis)
Note that the serial iterative base cases have the same func for A,B,C and D
    2) Also Note that you have to construct parallel iter base cases from this

Convert to T r-way R-DP using memory hierarchies now (Pg 107)
	Disk -> RAM -> GPU global memory -> GPU shared memory
	Let input DP table be present at level h (h = 3) which is on the disk
	3) Only 1 host-disk-A function is present, as the top level will have only 
	   1 recursive function,  it just splits the n x n problem into r x r problems of size n/r x n/r
	   r is chosen such that n/r fits into the RAM
	   Host represents that the code runs on the CPU and the disk represents that the data is on the disk
	   This function copies the relevant submatrices to RAM and then invokes 4 functions 
	   host-RAM-A, host-RAM-B, host-RAM-C, host-RAM-D
		
	4) host-RAM-* splits each (n/r x n/r) into r' x r' problems of size (n/(r.r') x n/(r.r'))
			These functions copy the relevant submatrices to the GPU glob
			memory and invoke 4 other func dev-global-A, dev-global-B, dev-global-C, dev-global-D
			dev indicates that the code will be on the GPU in the next level,
			and global indicates that it will be in the GPU global memory
	
	5) dev-global-* splits the problem further into submatrices to invoke :
	6) dev-shared-* in which we use iterative kernels and use threads to perform the computations

For the CPU programs, the base case dimension length for the algorithms was set to 256 and we run 
iterative kernels inside each base case	(Don't know what this means)

