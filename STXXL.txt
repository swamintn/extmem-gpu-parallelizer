									STXXL THEORY
External memory computation, supports parallel disk algos, overlap of IO and computn,
streams from one algo compo to another to avoid storing temp results in ext stg

Parallel disk algos
	An I/O operation transfers a block of B consecutive elements(cache size) 
	from/to a disk to amortize the latency. 
	The application tries to transfer D blocks between the main memory of size M bytes 
	and D independent disks in one I/O step to improve bandwidth.
	The input size is N bytes which is (much) larger than M. The main complexity metrics of 
	an I/O-efficient algorithm in PDM are the number of I/O steps (main metric) and the 
	number of operations executed by the CPU

Vector op
	Look at how vector op improves speed from array iteration to iterator to buffering & prefetching


									IMPORTANT RULES

CMake file has several build options. By setting them with "-DBUILD_EXAMPLES=ON -DBUILD_TESTS=ON" 
on the CMake line, additional subprojects are added to the build.

By default, STXXL compiles in Debug mode and includes many assertions and run-time checks, 
which typically slow down performance dramatically. To use STXXL at full speed, 
please set the build type to Release by adding -DCMAKE_BUILD_TYPE=Release to the cmake line



									STXXL DOWNLOAD AND SETUP
http://stxxl.org/tags/1.4.1/install_unix.html

If cmake does not work, add /usr/local/lib, /usr/lib and /usr/lib64 to the LD_LIBRARY_PATH

Alternate link to install STXXL		:	http://stxxl.org/tags/1.3/installation_linux_gcc.html

Some doubt				:	http://forums.codeguru.com/showthread.php?509173-Precompiled-headers-makefile

STEPS TO FACILITATE STXXL WITH CPU
	1)	Go to <project-directory> and do a cmake with icpc as -DCMAKE_CXX_COMPILER=icpc and
        -DCMAKE_C_COMPILER=icc
	2)	Then include cilk headers in stxxl-proj-folder/include	->	This step not needed anymore
		Instead of the above, we can just add the /opt/intel/include folder in CMakefiles.txt
        in the <project-directory>
	3)	Then set PATH to dyn lib of cilk by running source /opt/intel/bin/compilevars.sh <intel64>



									STXXL LANGUAGE
typedef stxxl::VECTOR_GENERATOR<unsigned int, 4, 8, 1*1024*1024, stxxl::RC, stxxl::lru>::result vector_type;
	PageSize is number of blocks per page(4), CachePages is number of pages(8),
    Block Size(2 MB) here it is 1 MB, Page Replacement (LRU)
	vector_type my_vector;

stxxl::random_number<> rand;
	tmp = rand(123456789); 

stxxl::uint64 number_of_elements = 32 * 1024 * 1024;

Input-Output
	vector has normal access which is faster than iterator-based access but is slower than buffered access
	(Refer to vector_buf.cpp)

File IO
	Normal IO
	Buffered IO (vector_buf.cpp)
	Streamed IO to prefetch blocks
	Streamed input and materialize output is faster than Streamed input and
	buffered output	which is faster than iterator i/o (as no prefetching)
